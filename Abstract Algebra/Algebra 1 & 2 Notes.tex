\documentclass[12pt, letterpaper]{report}

\usepackage{import}
\import{C:/Users/83tal/Documents/School}{header.tex}
\DeclareMathOperator{\cis}{cis}
\title{Algebra 1 and 2 Notes}
\author{Grant Talbert}
\date{Sem 2 2024}

\begin{document}
	\maketitle
	
	\begin{abstract}
		owo\\
		Notes from the text \emph{Abstract Algebra} by Thomas W. Judson.
	\end{abstract}
	
	\newpage
	
	\tableofcontents
	
	\newpage

\chapter{Preliminaries}
\section{Sets and Equivalence Relations}
\subsection*{Set Theory}
\begin{definition}[Set]
	A set is any well-defined collection of objects; that is, it is defined in such a manner that we can tell whether \(x\) belongs to the set or not.
\end{definition}
We denote sets by capital letters, and we refer to the objects that belong to them as their elements. We have two notations for defining sets. Sometimes we write all their elements within curly brackets:
\[
	X=\{ x_1,x_2,\ldots,x_n \} 
\]
and sometimes we use set-builder notation:
\[
	X=\{ x\mid x\text{ satisfies }\mathcal{P}   \} 
\]
where all elements \(x\) of the set \(X\) must satisfy some property \(\mathcal{P} \). For example, consider the set of even positive integers:
\[
	E=\{ x\in\mathbb{N} \mid \frac{x}{2}\in\mathbb{N}  \}
\]
We write \(2\in E\) to denote set membership, and \(-3\notin E\) to denote set exclusion.\\
The following are shorthands for rather important sets:
\begin{itemize}
	\item \(\mathbb{N} \) is the set of all naturals.
	\item \(\mathbb{Z} \) is the set of all integers. 
	\item \(\mathbb{Q} \) is the set of all rationals. 
	\item \(\mathbb{R} \) is the set of all reals. 
	\item \(\mathbb{C} \) is the set of all complex numbers.
\end{itemize}
We can define various relations and operations on sets.
\begin{definition}[Subset]
	if \(A\) and \(B\) are sets, we say that \(A\subset B\), or \(A\) is a subset of \(B\), if every element of \(A\) is also in \(B\).
\end{definition}
For example,
\[
	\mathbb{N} \subset\mathbb{Z} \subset\mathbb{Q} \subset\mathbb{R} \subset\mathbb{C} 
\]
Trivially, all sets are their own subsets. We also find that two sets are equal if \(A\subseteq B\) and \(B\subseteq A\).
\begin{definition}[Empty Set]
	The empty set, denoted \(\varnothing \), is the set \(\{  \} \).
\end{definition}
We can define two operations on sets to construct new sets from two sets:
\begin{definition}[Union]
	The union \(A\cup B\) of two sets \(A\) and \(B\) is defined as 
	\[
		A\cup B=\{ x\mid x\in A \lor x\in B\} 
	\]
	In other words, all elements in either \(A\), \(B\), or both.
\end{definition}
\begin{definition}[Intersection]
	The intersection \(A\cap B\) of two sets \(A\) and \(B\) is defined as 
	\[
		A\cap B=\{ x\mid x\in A \land x\in B \} 
	\]
	In other words, all elements in both \(A\) and \(B\).
\end{definition}
We can consider the union and intersection of more than just two sets with the big operators. The union is given as
\[
	\bigcup_{i=1}^{n} A_i =A_1 \cup A_2 \cup \cdots \cup A_n
\]
and the intersection is
\[
	\bigcap_{i=1}^{n} A_i = A_1 \cap A_2 \cap  \cdots \cap  A_n
\]
\begin{definition}[Disjoint]
	Two sets \(A\) and \(B\) are disjoint if 
	\[A\cap B=\varnothing\]
\end{definition}
Oftentimes, we will work within one fixed set \(U\), called the \emph{Universal Set.}
\begin{definition}[Compliment of a Set]
	From the previous definition of a Universal Set, we define the compliment of a set \(A\) as
	\[
		A^{\prime} =\{ x\mid x\in U \land x\notin A \} 
	\]
\end{definition}
\begin{definition}[Set Difference]
	We define the difference between two sets \(A\) and \(B\) as
	\[
		A\setminus B=A\cap B^{\prime} =\{ x\mid x\in A \land  x\notin B \} 
	\]
\end{definition}
\begin{proposition}
	Let \(A\), \(B\), and \(C\) be sets.
	\begin{itemize}
		\item \(A\cup A=A,A\cap A=A,\text{ and }A\setminus A=\varnothing \) 
		\item \(A\cup \varnothing =A \text{ and } A\cap \varnothing =\varnothing \) 
		\item \(A\cup (B\cup C)=(A\cup B)\cup C\text{ and }A\cap (B\cap C)=(A\cap B)\cap C \)
		\item \(A\cup B=B\cup A\) and \(A\cap B=B\cap A\)
		\item \(A\cup (B\cap C)=(A\cup B)\cap (A\cup C)\)
		\item \(A\cap (B\cup C)=(A\cap B)\cup (A\cap C)\)
	\end{itemize}  
\end{proposition}
\subsection*{Cartesian Products and Mappings}
Given sets \(A\) and \(B\), we define the \textbf{Cartesian} \textbf{Product} \(A\times B\) as a set of ordered pairs.
\begin{definition}[Cartesian Product]
	The cartesian product of two sets \(A\times B\) is given as
	\[
		A\times B=\{ (a,b)\mid a\in A \land b\in B \} 
	\]
\end{definition}
\begin{proposition}[Generalization of Cartesian Product]
	The cartesian product generalizes to \(n\) sets:
	\[
		A_1 \times \cdots \times A_n =\{ (a_1,\ldots,a_n)\mid a_1\in A_1 \land \cdots \land a_n\in A_n \} 
	\]
\end{proposition}
We will often use the shorthand \(\mathbb{R} \times \mathbb{R} \times \mathbb{R} =\mathbb{R} ^3\).
\begin{definition}[Function/Mapping]
	Subsets of \(A\times B\) are known as \textbf{relations}. We define a \textbf{mapping} or \textbf{function} \(f\subset A\times B\) from set \(A\) to \(B\) as a special type of relation where each element \(a\in A\) has a unique element \(b\in B\) such that \((a,b)\in f\).\\
	Often, we write \(f:A\to B\) and \(f:a\mapsto b\).
\end{definition}
If \(f:A\to B\), then \(A\) is the \textbf{domain} of \(f\), and
\[
	f(A)=\{ f(a)\mid a\in A \} \subseteq B
\]
is the \textbf{range} or \textbf{image} of \(f\).
\begin{definition}[Surjective]\label{surjective}
	A map \(f:A\to B\) is \textbf{onto} or \textbf{surjective} if
	\[
		\forall (a\in A)(\exists (b\in B)(f(a)=b))
	\]
	In other words, every element of the domain is mapped to an element in the image, \textbf{and} every element in the image is mapped from an element in the domain. The entirety of both sets is used.
\end{definition}
\begin{definition}[Injective]\label{injective}
	A map \(f:A\to B\) is \textbf{one-to-one} or \textbf{injective} if\\
	\[a_1\neq a_2 \Longrightarrow f(a_1)\neq f(a_2)\]
	Equivalently, a function is injective if \(a_1=a_2\Longrightarrow f(a_1)=f(a_2)\).\\
	In other words, each element of the domain is mapped to a \textbf{unique} element of the image.
\end{definition}
\begin{definition}[Bijective]\label{bijective}
	A map is called \textbf{bijective} if it is both injective and surjective.
\end{definition}
\begin{definition}[Function Compositions]
	If we have the maps \(f:A\to B\) and \(g:B\to C\), we can define the \textbf{composition} of \(f\) and \(g\) from \(A\) to \(C\) as 
	\[
		(g\circ f)(x)=g(f(x))
	\]
	where we have
	\[
		g\circ f:A\to C
	\]
\end{definition}
A map from \(\mathbb{R} ^n\) to \(\mathbb{R} ^m\) given by a matrix is known as a \textbf{linear} \textbf{map}, or \textbf{linear} \textbf{transformation}.
\begin{definition}[Permutation]\label{permutation}
	For some set \(S\), a bijection from \(S\) to \(S\), formally \(\pi:S\to S\), is known as a \textbf{permutation} of \(S\).
\end{definition}
\begin{theorem}[Properties of Compositions]\label{propcomp}
Let \(f:A\to B\), \(g:B\to C\), and \(h:C\to D\). 
\begin{itemize}
	\item The composition of mappings is associative: \((h\circ g)\circ f=h\circ (g\circ f)\)
	\item If \(f\) and \(g\) are both injective, then \(g\circ f\) is injective.
	\item If \(f\) and \(g\) are both surjective, then \(g\circ f\) is surjective. 
	\item If \(f\) and \(g\) are both bijective, then \(g\circ f\) is bijective.
\end{itemize}
\end{theorem}
\begin{definition}[Identity Mapping]\label{identity_map}
	For some set \(S\), we will use \(id_S\) or \(id\) as the \textbf{identity} \textbf{mapping} from \(S\) to itself.
	\[
		id(s)=s\forall s\in S
	\]
\end{definition}
\begin{definition}[Inverse Mappings]\label{invmap}
	From \ref{identity_map}, we can formally define an \textbf{inverse} \textbf{mapping} \(g:B\to A\) of some map \(f:A\to B\), where
	\[g\circ f=id_A \text{ and } f\circ g=id_B\]
\end{definition}
A map is said to be \textbf{invertible} if it has an inverse. We often give \(f^{-1} \) as the inverse of \(f\).
\begin{theorem}
	\textbf{A Map is Invertible if and only if it is Bijective.}
\end{theorem}
\begin{proof}
	Suppose \(f:A\to B\) is invertible with inverse \(g:B\to A\). Then \(g\circ f=id_A\) is the identity map, meaning \(g(f(a))=a\). If \(a_1,a_2\in A\) with \(f(a_1)=f(a_2)\), then
	\[
		a_1=g(f(a_1))=g(f(a_2))=a_2
	\]
	Thus, \(f\) is injective. Now suppose \(b\in B\). Let \(a\in A\) be the number such that \(f(a)=b\). Recall that \(f(g(b))=b\). Thus, we have \(a=g(b)\). This means each element of the domain will have some corresponding element in the image, and thus \(f\) is surjective.\\
	Let \(f\) be bijective and let \(b\in B\). Since \(f\) is surjective, there exists \(a\in A\) where \(f(a)=b\). Since \(f\) is injective, \(a\) is unique. Define \(g(b)=a\). This is the inverse of \(f\).
\end{proof}
\begin{definition}[Equivalent Relation]
	An equivalence relation on a set \(X\) is a relation \(R\subset X\times X\) satisfying the properties
	\begin{itemize}
		\item \((x,x)\in R\;\forall x\in X\) \textbf{reflexive} \textbf{property} 
		\item \((x,y)\in R\Longrightarrow (y,x)\in R\) \textbf{symmetric} \textbf{property} 
		\item \((x,y)\in R\) and \((y,z)\in R\) implies \((x,z)\in R\) \textbf{transitive} \textbf{property}
	\end{itemize}
\end{definition}
For an equivalence relation on \(X\) with \((x,y)\in R\), we often write \(x \sim y\). If the relation has an associated notation such as \(=,\equiv ,\cong \), then that will be used.
\begin{eg}
	Suppose \(f\) and \(g\) are differentiable functions on \(\mathbb{R} \). We can define an equivalence relation \(f(x)\sim g(x)\) if \(f^{\prime} (x)=g^{\prime} (x)\).
\end{eg}
\begin{definition}[Partition]
	A partition \(\mathcal{P} \) of a set \(X\) is a collection of sets \(X_1,X_2,\ldots\neq \varnothing \) such that
	\[X_{i} \cap X_j = \varnothing \text{ for }i\neq j\]
	and
	\[\bigcup_{k}X_k=X\]
\end{definition}
\begin{definition}[Equivalence Class]
	Let \(\sim \) be an equivalence relation on a set \(X\) with \(x\in X\). Then the \textbf{equivalence} \textbf{class} of \(x\) is given as 
	\[
		[x]=\{ y\in X\mid y\sim x \} 
	\]
\end{definition}
\begin{theorem}
	Given an equivalence relation \(\sim \) on a set \(X\), the equivalence classes of \(X\) form a partition of \(X\). Conversely, if \(\mathcal{P} ={X_i}\) is a partition of a set \(X\), then there is an equivalence relation on \(X\) with equivalence classes \(X_i\).
\end{theorem}
\begin{corollary}
	Two equivalence classes of an equivalence relation are either disjoint or equal.
\end{corollary}
\chapter{The Integers}
\section{Mathematical Induction}
\begin{definition}[First Principle of Induction]
	Mathematical induction is a method of proof wherein a statement about integers with \(n\in\mathbb{N} \). We prove the statement for a specific integer \(n_0\), and then we show that the statement being true for some \(n\) implies the statement is true for \(n+1\). This implies this statement holds for all integers \(n\geq n_0\).
\end{definition}
A standard example of induction follows. 
\begin{eg}
	Show that
	\[
		1+2+\cdots+n=\frac{n(n+1)}{2}
	\]
	for any \(n\in\mathbb{N} \).\\
	We can show this for \(n=1\):
	\[
		1=\frac{1(1+1)}{2}=\frac{2}{2}=1
	\]
	Now we can assume that we have verified the first \(n\) cases.
	\[
		1+\cdots+n+(n+1)=\frac{n(n+1)}{2}+n+1
	\]
	\[
		=\frac{n^{2+3n+2} }{2}
	\]
	\[
		=\frac{(n+1)((n+1)+1)}{2}
	\]
	This is the formula for the \(n+1\)th case, so we are done.
\end{eg}
\begin{definition}[Second Principle of Induction]
	Let \(S(n)\) be a statemenht about the integers for \(n\in\mathbb{N} \). Suppose \(S(n_0)\) is true. If \(S(n_0),S(n_{0}+1 ),\ldots,S(k)\) implies \(S(k+1)\) for \(k\geq n_0\), then \(S(n)\) is true for all integers \(n\geq n_{0} \).
\end{definition}
This is more complicated, so an example has not been given. Obviously.
\begin{definition}[Principle of Well-Ordering]
	Every nonempty subset of the natural numbers is well-ordered.
\end{definition}
\begin{lemma}
	The principle of mathematical induction implies \(1\) is the least positive natural.
\end{lemma}
\begin{theorem}[Principle of Well-Ordering]
	The principle of well ordering can follow from the principle of mathematical induction. Furthermore, every nonempty subset of \(\mathbb{N} \) contains at least one element.
\end{theorem}
\section{The Division Algorithm}

\begin{theorem}[Division Algorithm]\label{divalg}
	Let \(a\) and \(b\) be integers with \(b>0\). Then there exists \emph{unique} integers \(q\) and \(r\) such that 
	\[
		a=bq+r
	\]
	where \(0\leq r<b\).
\end{theorem}
Let \(a,b\in\mathbb{Z} \). If \(b=ak,k\in\mathbb{Z} \), then we write \(a|b\). We say an integer \(d\) is a \textbf{common} \textbf{divisor} of \(a\) and \(b\) if \(d|a\) and \(d|b\). The \textbf{greatest} \textbf{common} \textbf{divisor} of integers \(a,b\) is a positive integer \(d\) such that \(d\) is a common divisor of \(a\) and \(b\) and if \(d^{\prime} \) is any other common divisor of \(a\) and \(b\), then \(d^{\prime} |d\). We write \(\text{gcd}(a,b) \).
\begin{definition}[Relatively Prime Numbers]
	Two numbers \(a,b\in\mathbb{Z} \) are relatively prime if \(\text{gcd}(a,b)=1 \).
\end{definition}
\begin{theorem}\label{owothingy}
	Let \(a,b\in\mathbb{Z} \setminus \{ 0 \} \). Then there exist \(r,s\in\mathbb{Z} \) such that 
	\[
		\text{gcd}(a,b)=ar+bs 
	\]
\end{theorem}
\begin{corollary}
	For any two \(a,b\in\mathbb{Z} \) that are relatively prime, there exist \(r,s\in\mathbb{Z} \) such that \(ar+bs=1\).
\end{corollary}
\subsection*{The Euclidean Algorithm}
\ref{owothingy} allows us to compute the gcd of two integers. This will be illustrated with an example.
\begin{eg}
	Let's compute \(\text{gcd}(945,2415) \). First, observe:
	\begin{align*}
		2415&=945\cdot2+525\\
		945&=525\cdot1+420\\
		525&=420\cdot1+105\\
		420&=105\cdot4+0
	\end{align*}
	Reversing our steps, we find that \(105\) divides \(420\), \(105\) divides \(525\), \(105\) divides \(945\), and \(105\) divides \(2415\). Hence, \(105\) divides both numbers. If \(d\) were another common divisor of \(945\) and \(2415\), then \(d\) would have to divide \(105.\) Hence, \(\text{gcd}(2415,945)=105 \).
\end{eg}
To compute \(\text{gcd}(a,b) =d\), we are dividing multiple times to obtain a decreasing sequence of integers. We use the algorithm
\begin{align*}
	b&=aq_1 +r_1\\
	a&=r_1 q_2 +r_2\\
	r_1&=r_2 q_3 +r_3\\
	&\vdots\\
	r_{n-2}&=r_{n-1}q_n +r_n\\
	r_{n-1}&=r_n q_{n+1}
\end{align*}
where \(q_i\) is the highest integer number of times \(r_i\) can divide \(r_{i-1} \), and \(r_{i+1} \) is the remainder. 
\subsection*{Prime Numbers}
Some \(p\in\mathbb{N} \setminus \{ 1 \} \) is a \textbf{prime} \textbf{number} if the only numbers that divide \(p\) are 1 and itself. Non-prime integers \(>1\) are known as \textbf{composite}.
\begin{lemma}[Euclid]
	Let \(a,b\in\mathbb{Z} \) and \(p\in\mathbb{P} \), where \(\mathbb{P} \) is the set of primes. Since \(\text{gcd}(a,p)=1 \), then there exists \(r,s\in\mathbb{Z} \) such that \(ar+ps=1\).
\end{lemma}
\begin{theorem}[Euclid]
	There exist an infinite number of primes.
\end{theorem}
\begin{proof}
	We will do this proof via contradiction. Suppose there are a finite number of primes, say \(\{ p_1,\ldots,p_n \}=\mathbb{P}  \).
	\[
		\text{Let } P=1+\prod _{i\in\mathbb{P} }i
	\]
	It follows that \(P\) is divisible by some \(p_i\) for \(i\in[1,n]\). In this case, \(p_i\) must divide \(P-p_1 p_2 \cdots p_n=1\). However, it does not, so there must either exist some \(p_{n+1}\neq p_i \), or \(P\in\mathbb{P} \).
\end{proof}
\begin{theorem}[Fundamental Theorem of Arithmetic]
	Let \(n\in\mathbb{N} \) where \(n>1\). Then 
	\[
		n=p_1 p_2 \cdots p_k
	\]
	where \(p_1,\ldots,p_k\in\mathbb{P} \), and are not necessarily distinct. Furthermore, this factorization is unique.
\end{theorem}


\chapter{Groups}
\section{Integer Equivalence Classes and Symmetries}
Two integers \(a,b\in\mathbb{Z} \) are equivalent mod \(n\) if \(n\) divides \(a-b\) with no remainder. The integers mod \(n\) partition \(\mathbb{Z} \) into \(n\) different equivalence classes, the set of which is denoted as \(\mathbb{Z} _n\). For example, consider \(\mathbb{Z} _{12}\), the set of the following equivalence classes:
\begin{align*}
	[0]&=\{ \ldots,-12,0,12,24,\ldots \}\\
	[1]&=\{ \ldots,-11,1,13,25,\ldots \}\\
	&\vdots\\
	[11]&=\{ \ldots,-1,11,23,35,\ldots \}
\end{align*}
We can define arithmetic over \(\mathbb{Z} _n\), where we say addition modulo \(n\) is given as \((a+b)\mod n\).
\begin{eg}
	Operations modulo \(n\):
	\begin{align*}
		7+4&\equiv 1\mod5&7\cdot3&\equiv 1\mod5\\
		3+5&\equiv 0\mod8&3\cdot5&\equiv 7\mod8\\
		3+4&\equiv 7\mod12&3\cdot4&\equiv0\mod12
	\end{align*}
\end{eg}
\begin{proposition}\label{prop.1}
	Let \(\mathbb{Z} _n\) be the set of equivalence classes of the integers mod \(n\) and \(a,b,c\in\mathbb{Z} _n\).
	\begin{enumerate}
		\item Addition and multiplication are commutative:
		\[
			a+b\equiv b+a\mod n
		\]
		\[
			ab\equiv ba\mod n
		\]
		\item Addition and multiplication are associative:
		\[
			(a+b)+c\equiv a+(b+c)\mod n
		\]
		\[
			(ab)c\equiv a(bc)\mod n
		\]
		\item There are both additive and multiplicative identities:
		\[
			a+0\equiv a\mod n
		\]
		\[
			a\cdot 1\equiv a\mod n
		\]
		\item Multiplication distributes over addition:
		\[
			a(b+c)\equiv ab+ac\mod n
		\]
		\item For every integer there exists an additive inverse:
		\[
			a+(-a)\equiv 0\mod n
		\]
		\item If \(a\neq 0\), then \(\text{gcd}(a,n)=1 \) iff there exists a multiplicative inverse \(b\) for \(a\mod n\); that is, a \(b\neq 0\) such that 
		\[
			ab\equiv 1\mod n
		\]
	\end{enumerate}
\end{proposition}
\section{Definitions and Examples}
\begin{definition}[Group]\label{group}
	A group \((G,\circ )\)  is a set \(G\) together with a \textbf{binary} \textbf{operation} (or \textbf{law} \textbf{of} \textbf{composition}) \(G\times G\to G\) given as \((a,b)\mapsto a\circ b\) that satisfies the following axioms. 
	\begin{itemize}
		\item The binary operation is \textbf{associative}. That is, 
		\[
			(a\circ b)\circ c=a\circ (b\circ c)
		\]
		Formally,
		\[
			\forall (a,b,c\in G)((a\circ b)\circ c=a\circ (b\circ c))
		\]
		\item There exists an \textbf{identity} \textbf{element} \(e\in G\), such that
		\[
			e\circ a=a\circ e=a
		\]
		Formally,
		\[
			\exists (e\in G)(\forall a\in G(a\circ e=e\circ a=a))
		\]
		\item For all \( a\in G\), there exists an \textbf{inverse} \textbf{element} \(a^{-1} \in G\), such that 
		\[
			a\circ a^{-1} =a^{-1} \circ a=e
		\]
		Formally,
		\[
			\forall (a\in G)(\exists (a^{-1} \in G)(a\circ a^{-1} =a^{-1} \circ a=e))
		\]
	\end{itemize}
	The \(\circ \) operator can be thought of as simply a placeholder for a binary operation such as addition, multiplication, or even an inner product-like operation.
\end{definition}
\begin{definition}[Abelian Group]\label{abelian}
	A group \((G,\circ )\) with the property \(a\circ b=b\circ a\;\forall a,b\in G\) is called \textbf{abelian} or \textbf{commutative}. A group not satisfying this property is known as \textbf{nonabelian} or \textbf{noncommutative}.
\end{definition}
\begin{notation}
	We will use \(ab\) to denote a binary operation associated with a set rather than \(a\circ b\), partially for brevity but also to distinguish between group opperations and compositions. If a standard symbol is associated with the operation, such as \(+\), that will be used instead.
\end{notation}
For example, the set of integers \(\mathbb{Z} \) forms a group under addition, because for all \(a,b\in\mathbb{Z} \), we have \((a+b)\in\mathbb{Z} \), \(a+0=a\), \(a+(-a)=0\), and \(-a\in\mathbb{Z} \). We also have \(a+b=b+a\), so the integers over addition \((\mathbb{Z} ,+)\) form an abelian group.\\
The integers mod \(n\) also form a group under addition modulo \(n\). Addition can be shown with a \textbf{Cayley} \textbf{table}, or a table describing addition/multiplication. Consider \(\mathbb{Z} _5\):\\
\begin{center}\begin{tabular}{c|ccccc}
	+&0&1&2&3&4\\
	\hline
	0&0&1&2&3&4\\
	1&1&2&3&4&0\\
	2&2&3&4&0&1\\
	3&3&4&0&1&2\\
	4&4&0&1&2&3
\end{tabular}\end{center}
It's also to note that not every set with a binary operation defines a group. For example, the integers mod \(n\) are not necessarily closed under multiplication, so they cannot necessarily constitute a group. However, we can recall from \ref{prop.1} that \(ab\equiv 1\mod n\) iff \(a,b\) are relatively prime; that is \(\text{gcd}(a,b)=1 \). Thus, we can define the multiplicative group of nonzero relatively prime numbers in \(\mathbb{Z} _n\) as \(U(n)\). For example, consider the Cayley table for \(U(8)\):\\
\begin{center}
	\begin{tabular}{c|cccc}
		\(\cdot\)&1&3&5&7\\
		\hline
		1&1&3&5&7\\
		3&3&1&7&5\\
		5&5&7&1&3\\
		7&7&5&3&1\\ 
	\end{tabular}
\end{center}
\begin{eg}
	Let
	\[
		1=\begin{pmatrix}
			1 &0   \\
			 0&  1 \\
		\end{pmatrix}\qquad \hat{\imath}=\begin{pmatrix}
			 0&1   \\
			 -1&  0 \\
		\end{pmatrix}
	\]
	\[
		\hat{\jmath}=\begin{pmatrix}
			0 &i   \\
			 i&  0 \\
		\end{pmatrix}\qquad \hat{k}=\begin{pmatrix}
			i &0   \\
			 0&  -i \\
		\end{pmatrix}
	\]
	Notice the following. 
	\[
		\hati^2=\begin{pmatrix}
			0 &1   \\
			 -1&  0 \\
		\end{pmatrix}\begin{pmatrix}
			0 &1   \\
			 -1&  0 \\
		\end{pmatrix}=\begin{pmatrix}
			-1 &0   \\
			 0&-1   \\
		\end{pmatrix}=-1
	\]
	\[
		\hatj^2=\begin{pmatrix}
			0 &i   \\
			 i&  0 \\
		\end{pmatrix}\begin{pmatrix}
			0 &i   \\
			 i&  0 \\
		\end{pmatrix}=\begin{pmatrix}
			-1 &0   \\
			 0&-1   \\
		\end{pmatrix}=-1
	\]
	\[
		\hatk^2=\begin{pmatrix}
			i &0   \\
			 0&  -i \\
		\end{pmatrix}\begin{pmatrix}
		i &0   \\
		 0&  -i \\
	\end{pmatrix}=\begin{pmatrix}
		-1 &0   \\
		 0&-1   \\
	\end{pmatrix}=-1
	\]
	\[
		\Longrightarrow \hati^2 =\hatj^2 =\hatk^2=-1
	\]
	The set \(Q_8 =\{ \pm1,\pm\hati,\pm\hatj,\pm\hatk \} \) forms a group \(\left( Q_8,\cdot \right) \) known as the \textbf{quaternion} \textbf{group}, which is nonabelian.
\end{eg}
One final important example is the \textbf{general} \textbf{linear} \textbf{group}. This is the group of all invertible matrices over the multiplication operator, and is denoted \(\text{GL}(n,S) \) where the matrices are of order \(n\) with elements \(a_{ij} \in S\).
\begin{definition}[Order of a Group]
	The order of a group \(G\), denoted \(|G|\), is the number of elements it has. If the group has \textbf{finite} \textbf{order}, we write \(|G| =n\), where \(n\in\mathbb{N} \). If a group has \textbf{infinite} \textbf{order}, we write \(|G| =\infty\).
\end{definition}
\subsection*{Basic Properties of Groups}
\begin{proposition}
	The identity element of a group is unique. 
\end{proposition}
\begin{proof}
	Suppose \(e\) and \(e^{\prime} \) are both identities in \(G\). Then \(eg=ge=g\) and \(e^{\prime} g=ge^{\prime} =g\) for all \(g\in G\). However, \(e,e^{\prime} \in G\), so we can say
	\[
		ee^{\prime} =e^{\prime} 
	\]
	\[
		ee^{\prime} =e
	\]
	\[
		\Longrightarrow e=ee^{\prime}=e^{\prime} 
	\]
	\[
		\therefore e=e^{\prime} 
	\]
\end{proof}
\begin{proposition}
	If \(G\) is a group, then for any \(g\in G\), its inverse \(g^{-1} \) is unique.
\end{proposition}
\begin{proposition}
	Let \(G\) be a group. If \(a,b\in G\), then \((ab)^{-1} =b^{-1} a^{-1} \).
\end{proposition}
\begin{proof}
	Let \(a,b\in G\). Then \(abb^{-1} a^{-1} =aea^{-1} =aa^{-1} =e\). Similarly, \(b^{-1} a^{-1} ab=e\). By the previous proposition, we know that inverses are unique, and by \ref{group} we know group operations are associative. Thus,
	\[
		(ab)\left( b^{-1} a^{-1}  \right) =e
	\]
	\[
		\therefore (ab)^{-1} =b^{-1} a^{-1} 
	\]
\end{proof}
\begin{proposition}
	If \(G\) is a group, then \(\forall a\in G\), it will follow that \(\left( a^{-1}  \right)^{-1} =a \).
\end{proposition}
\begin{proposition}
	If \(G\) is a group and \(a,b,c\in G\), then \(ba=ca\Longrightarrow b=c\) and \(ab=ac\Longrightarrow b=c\).
\end{proposition}
The previous proposition shows that \textbf{right and left cancellation laws} hold in groups. This is due to the existance of inverses over the associated binary operation.
\begin{notation}
	Oftentimes, exponential notation will be used in a group to denote repeated applications of the operation:
	\[
		g^n=\underbrace{g\circ g\circ \cdots\circ g}_{n\text{ times} }
	\]
	And
	\[
		g^{-n} =\underbrace{g^{-1} \circ g^{-1} \circ \cdots\circ g^{-1} }_{n\text{ times} }
	\]
\end{notation}
\begin{proposition}
	In a group \(G\), the following properties of exponentiation hold for all \(g,h\in G\):
	\begin{itemize}
		\item \(g^m g^n=g^{m+n} \;\forall m,n\in\mathbb{Z} \) 
		\item \(\left( g^m \right)^n=g^{mn}\;\forall m,n\in\mathbb{Z}   \)
		\item \((gh)^n =\left( h^{-1} g^{-1}  \right)^{-n}\;\forall n\in \mathbb{Z}   \)
	\end{itemize}
\end{proposition}
\begin{remark}
	In the above proposition, \((gh)^n \neq g^n h^n\) in general, since the group may not be abelian. If the group is abelian, this property holds.
\end{remark}
\begin{remark}
	f the group has an addition operator, especially if the group is \(\mathbb{Z} \) or \(\mathbb{Z} _n\), we write the operation of exponentiation as multiplication, that is \(an\) rather than \(n^a\) for \(n\in G\), \(a\in\mathbb{Z} \).
\end{remark}
\section{Subgroups}
\subsection*{Definitions and Examples}
\begin{definition}[Subgroup]
	A \textbf{subgroup} \(H\) of a group \(G\) is a subset \(H \subseteq G\) such that when the group operation of \(G\) is restricted to \(H\), then \(H\) is still a group. That is, if \(H\subseteq G\) and \((G,\circ )\) is a group, then \(H\) is a subgroup if \((H,\circ )\) is a group.
\end{definition}
\begin{remark}
	The subgroup \(H=\{ e \} \) is called the \textbf{trivial} \textbf{subgroup}, and a proper subset that forms a group \(H \subsetneq G\) is known as a \textbf{proper} \textbf{subgroup}.
\end{remark}
\begin{eg}
	Consider the set of nonzero real numbers \(\mathbb{R} ^*\) over the operation of multiplication. The identity is \(1\) and the inverse of any \(a\in\mathbb{R} ^*\) is just \(a^{-1} \). We can show that \(\mathbb{Q} ^*\) is a proper subgroup of \(\mathbb{R} ^*\). Trivially, \(1\in\mathbb{Q}^* \). Also, the inverse of any \(\frac{p}{q}\in\mathbb{Q}^* \) must also be in \(\mathbb{Q}^* \), since \(\left( \frac{p}{q} \right)^{-1} =\frac{q}{p}\in\mathbb{Q} ^*\). Since multiplication in \(\mathbb{R} ^*\) is associative, so is multiplication in \(\mathbb{Q} ^*\). Therefore, \(\mathbb{Q} ^*\) is a proper subgroup of \(\mathbb{R} ^*\).
\end{eg}
\begin{remark}
	A subset of some set \(G\) can be a group without being a \emph{subgroup} of \(G\), if it is a group under a different operation. For example, the general linear is not a subgroup of the additive group of \(n\times n\) matrices, since it uses a different operation.
\end{remark}
\begin{eg}
	Let \(\text{SL}(2,\mathbb{R} )\subset\text{GL}(2,\mathbb{R} )  \) be the set of matrices \(A\in\text{SL}(2,\mathbb{R} ) \) satisfying \(\det (A)=1\). Multiplication is closed since \(\det (A)\det (B)=\det (AB)\), and the other properties of groups follow directly from the general linear. This group is known as the \textbf{special linear group}.
\end{eg}
\subsection*{Some Subgroup Theorems}
\begin{proposition}
	A subset \(H\) of \(G\) is a subgroup iff it satisfies the following conditions:
	\begin{enumerate}
		\item The identity \(e\in G\) is in \(H\). 
		\item If \(h_1,h_2\in H\), then \(h_1 h_2\in H\).
		\item If \(h\in H\), then \(h^{-1} \in H\).
	\end{enumerate}
\end{proposition}
\begin{proof}
	Trivial.
\end{proof}
\begin{proposition}
	Let \(H\) be a subset of \(G\). Then \(H\) is a subgroup of \(G\) iff \(H\neq \varnothing \), and whenever \(g,h\in H\) then \(gh^{-1} \in H\).
\end{proposition}
\chapter{Cyclic Groups}
\section{Cyclic Subroups}
Oftentimes, a subgroup can be constructed from a single element of a group. For example, consider \(3\in\mathbb{Z} \). now consider the set of all multiples of 3, that is 
\[
	3\mathbb{Z} =\{ \ldots,-3,0,3,6,\ldots \} 
\]
Obviously, \(3\mathbb{Z} \) is a subgroup of \(\mathbb{Z}\). Specifically, it's a \textbf{cyclic subgroup} "generated" by 3. 
\begin{theorem}[Cyclic Subgroups]
	If \(G\) is a group and \(a\in G\), then the set 
	\[
		\langle a \rangle =\left\{ a^k \mid k\in\mathbb{Z}  \right\} 
	\]
	is a subgroup of \(G\). Furthermore, \(\langle a \rangle \) is the smallest subgroup of \(G\) containing \(a\).
\end{theorem}
\begin{remark}
	If we use the \(+\) notation, then we write 
	\[
		\langle a \rangle =\left\{ na \mid n\in\mathbb{Z}  \right\}
	\]
\end{remark}
\begin{definition}[Cyclic Groups and Subgroups]
	If \(G\) is a group with \(a\in G\), then we say \(\langle a \rangle \) is the \textbf{cyclic} \textbf{subgroup} generated by \(a\). If there exists some \(b\in G\) where \(\langle b \rangle =G\), then \(G\) is a \textbf{cyclic} \textbf{group} generated by \(b\). We call \(a\) and \(b\) the \textbf{generators} of their repsective groups.
\end{definition}
\begin{definition}[Order of a Cyclic Group]
	The \textbf{order} of a cyclic group \(\langle a \rangle \) is the smallest \textbf{positive} integer \(n\in\mathbb{Z} ^+\) such that \(a^n =e\), where \(e\in \langle a \rangle \) is the identity element. If there does not exist some \(n\), we say \(|a| =\infty\).
\end{definition}
\begin{remark}
	When considering the above definition, it's important to note that \(0\notin \mathbb{Z} ^+\).
\end{remark}
\begin{eg}
	Notice that both \(1\) and \(5\) generate \(\left( \mathbb{Z} _6,+ \right) \). Also, not every element necessarily generates the group. The element \(2\in\mathbb{Z} _6\) generates \(\langle 2 \rangle =\left\{ 0,2,4 \right\} \).
\end{eg}

\begin{theorem}
	Every cyclic subgroup is abelian.
\end{theorem}
\begin{proof}
	Let \(\langle a \rangle =G\) and \(a\in G\). If \(g,h\in G\), then they can be written as powers of \(a\). Let \(r,s\in\mathbb{Z} \) such that \(g=a^r ,h=a^s\). 
	\[
		gh=a^r a^s=a^{r+s}=a^{s+r}=a^s a^r =hg   
	\]
	Therefore \(G\) is abelian.
\end{proof}
\subsection*{Subgroups of Cyclic Groups}
\begin{theorem}
	Every subgroup of a cyclic group is cyclic.
\end{theorem}
\begin{corollary}
	The subgroups of \(\mathbb{Z} \) are exactly \(n\mathbb{Z} \) for \(n\in\mathbb{N} \cup \{ 0 \} \). 
\end{corollary}
\begin{proposition}
	Let \(G\) be a cyclic subgroup of order \(n\) and suppose \(\langle a \rangle=G \). Then \(a^k =e\) iff \(n\) divides \(k\) with no remainder.
\end{proposition}
\begin{theorem}
	Let \(G\) be a cyclic group of order \(n\) with \(\langle a \rangle =G\). If \(b=a^k\), then the order of \(b\) is \(\frac{n}{d}\), where \(d=\text{gcd}(k,n) \).
\end{theorem}
\begin{corollary}
	The generators of \(\mathbb{Z} _n\) are the integers \(r\in[1,n)\) where \(\text{gcd}(r,n)=1 \).
\end{corollary}
\section{Multiplicative Group of Complex Numbers}
\begin{definition}[Complex Numbers]
	The \textbf{complex} \textbf{numbers} are defined as
	\[
		\mathbb{C} =\left\{ a+bi\mid a,b\in\mathbb{R}  \right\} 
	\]
	where \(i=\sqrt{-1} \)
\end{definition}
\begin{definition}[Arithmetic in \(\mathbb{C} \)]
	If \(z=a+bi\) and \(w=c+di\) with \(z,w\in\mathbb{C} \), then we have 
	\[
		z+w=(a+bi)+(c+di)=(a+c)+(b+d)i
	\]
	\[zw=(a+bi)(c+di)=ac+bdi^2 +adi+bci =(ac-bd)+(ad+bc)i\]
\end{definition}
Every nonzero complex number \(z=a+bi\) has a multiplicative inverse, that is \(z^{-1} \in\mathbb{C} \) such that \(zz^{-1}=z^{-1} z=1\).
\[
	z^{-1} =\frac{a-bi}{a^2 +b^2}
\]
\begin{definition}[Complex Conjugate]
	If \(z=a+bi\), then the complex conjugate \(\overline{z}=a-bi\).
\end{definition}
Complex numbers can also be represented in \textbf{polar} \textbf{coordinates} of the form 
\[
	z=a+bi=r(\cos \theta +i\sin \theta )
\]
and
\[r=|z| =\sqrt{a^2 +b^2} \]
and
\[
	a=r\cos \theta \quad b=r\sin \theta 
\]
and
\[
	\theta =\arctan\left( \frac{b}{a} \right)
\]
\begin{notation}
	We can abbreviate \(r(\cos \theta +i\sin \theta )\eqqcolon r\cis \theta \).
\end{notation}
\begin{proposition}
	Let \(z=r\cis \theta \) and \(w=s\cis \phi \). Then
	\[
		zw=rs\cis(\theta +\phi )
	\]
\end{proposition}
\begin{theorem}[DeMoivre]
	Let \(z=r\cis \theta \in\mathbb{C} \setminus \{ 0 \} \). Then 
	\[
		\left( r\cis \theta  \right) ^n =r^n \cis(n \theta )
	\]
\end{theorem}
\subsection*{The Circle Group and the Roots of Unity}
The multiplicative group of complex numbers \((\mathbb{C} ,\cdot)\triangleq\mathbb{C} ^*\) has interesting subgroups. Specifically, \(\mathbb{R} ^*\) and \(\mathbb{Q} ^*\) have no subgroups of finite order, but \(\mathbb{C} ^*\) has many. 
\begin{definition}[Circle Group]\label{circlegroup}
	The circle group is the multiplicative group \(\mathbb{T} \subsetneq \mathbb{C} \) defined as 
	\[
		\mathbb{T} \coloneqq \left\{ z\in\mathbb{C} \mid |z| = 1 \right\} 
	\]
\end{definition}
\begin{remark}
	This group forms a circle on the complex grid with radius 1.
\end{remark}
\begin{proposition}
	The circle group \(\mathbb{T} \) is a subgroup of \(\mathbb{C} ^*\) 
\end{proposition}
The circle group has many interesting subgroups, such as \(\{ 1,-1,i,-i \} \). These numbers are the numbers satisfying \(z^4 =1\). These are known as the 4th \textbf{roots} \textbf{of} \textbf{unity}. 
\begin{definition}[Roots of Unity]
	The set of complex numbers \(z\) satisfying \(z^n =1\) for some \(n\in\mathbb{N} \) are known as the \(n\)\textbf{th} \textbf{roots} \textbf{of} \textbf{unity}.
\end{definition}
\begin{theorem}[Roots of Unity Definition]
	If \(z^n =1\), then the \(n\)th roots of unity are 
	\[z=\cis \left( \frac{2k \pi }{n} \right) \]
	where \(k\in\{ 0,1,\ldots,n-1 \} \). Furthermore, the \(n\)th roots of unity are a subgroup of \(\mathbb{T} \) of order \(n\).
\end{theorem}
\begin{definition}[Primitive \(n\)th root of unity]
	A primitive \(n\)th root of unity is some \(z\) that generates the \(n\)th roots of unity.
\end{definition}
For example, the 8th roots of unity have 4 generators: 
\begin{align*}
	w&=\frac{\sqrt{2} }{2}+\frac{\sqrt{2} }{2}i\\
	w^3 &=-\frac{\sqrt{2} }{2}+\frac{\sqrt{2} }{2}i\\
	w^5 &=-\frac{\sqrt{2} }{2} -\frac{\sqrt{2} }{2}i\\
	w^7 &=\frac{\sqrt{2} }{2}-\frac{\sqrt{2} }{2}i
\end{align*}
\section{The Method of Repeated Squares}
looked boring ill come back to it later 
\chapter{Permutation Groups}
Consider an equilateral triangle \(\triangle ABC\). The symmetries of this triangle actually consist of permutations of the three vetices, where a \textbf{permutation}  of the set \(S=\{ A,B,C \} \) is a bijective map \(\pi :S\to S	\). The three vertices have the following six permuations: 
\[
	\begin{pmatrix}
		A &B  &C   \\
		 A&B  &C   \\
	\end{pmatrix}\quad \begin{pmatrix}
		 A&B  &C   \\
		 C&A  &B   \\
	\end{pmatrix}\quad \begin{pmatrix}
		A &B  &C   \\
		 B&C  &A   \\
	\end{pmatrix}
\]
\[
	\begin{pmatrix}
		A &B  &C   \\
		 A&C  &B   \\
	\end{pmatrix}\quad \begin{pmatrix}
		A &B  &C   \\
		 C&B  &A   \\
	\end{pmatrix}\quad \begin{pmatrix}
		A &B  &C   \\
		 B&A  &C   \\
	\end{pmatrix}
\]
In this case, the array 
\[
	\begin{pmatrix}
		A &B  &C   \\
		 B&C  &A   \\
	\end{pmatrix}
\]
denotes the permuation that sends \(A\to B\), \(B\to C\), and \(C\to A\):
\[
	A\mapsto B
\]
\[
	B\mapsto C
\]
\[
	C\mapsto A
\]
The symmetries of a triangle form a group. In this chapter we study groups of this type.
\section{Definitions and Notation}
The permutations of a set \(X\) form a group \(S_X\). If \(X\) is finite, then we assume \(X=\{ 1,2,\ldots,n \} \). In this case we write \(S_n\) instead of \(S_X \). We call this the \textbf{symmetric} \textbf{group} on \(n\) letters. 
\begin{theorem}[Symmetric Group on \(n\) Letters]
	The symmetric group on \(n\) letters \(S_n\) is a group with \(n!\) elements, wherein the binary operation is the composition of maps.
\end{theorem}
\begin{proof}
	The identity of \(S_n\) is the identity map. If \(f:S_n \to S_n\) is a permutation, then \(f^{-1} \) exists by \ref{invmap} since \(f\) is bijective. Thus, every map has an inverse under the composition operation. By \ref{propcomp}, compositions are associative. Thus, \((S_n,\circ )\) is a group. There are \(n!\) ways to arrange sets of order \(n\), so \(\left\vert S_n \right\vert=n! \).
\end{proof}
\begin{definition}[Permutation Group]
	A subgroup of \(S_n\) is a \textbf{permutation} \textbf{group}.
\end{definition}
\begin{eg}
	Consider the subgroup \(G\) of \(S_5\) consisting of the identity permutation \(\text{id} \) and the permutations 
	\[
		\sigma =\begin{pmatrix}
			1 &2  &3  &4  &5   \\
			 1&2  &3  &5  &4   \\
		\end{pmatrix}
	\]
	\[
		\tau =\begin{pmatrix}
			1 &2  &3  &4  &5   \\
			 3&2  &1  &4 &5   \\
		\end{pmatrix}
	\]
	\[
		\mu =\begin{pmatrix}
			1 &2  &3  &4  &5   \\
			 3&2  &1  &5  &4   \\
		\end{pmatrix}
	\]
	We can construct this table defining how to operate with elements in this permutation group.
	\begin{center}\begin{tabular}{c|cccc}
		\(\circ \) &\(\text{id} \) &\(\sigma \) &\(\tau \) &\(\mu \)\\
		\hline
		\(\text{id} \) &\(\text{id} \) &\(\sigma \) &\(\tau \) &\(\mu \)\\
		\(\sigma \)&\(\sigma \)&\(\text{id} \)&\(\mu \)&\(\tau \)\\
		\(\tau \)&\(\tau \)&\(\mu \)&\(\text{id} \)&\(\sigma \)\\
		\(\mu \)&\(\mu \)&\(\tau \)&\(\sigma \)&\(\text{id} \)
	\end{tabular}\end{center}
\end{eg}
\begin{remark}
	Functions are composed from right to left. That is, \((\sigma \circ \tau )(x)=\sigma (\tau (x))\). We can thus adopt the convention of operating from right to left on permutations, that is given \(\sigma \tau \) we will simply do \(\tau \) first.
\end{remark}
\begin{eg}
	Permutation groups are usually not abelian. Let 
	\[
		\sigma =\begin{pmatrix}
			1 &2  &3  &4   \\
			 4&1  &2  &3   \\
		\end{pmatrix}
	\]
	\[
		\tau =\begin{pmatrix}
			1 &2  &3  &4   \\
			 2&1  &4  &3   \\
		\end{pmatrix}
	\]
	Then 
	\[
		\sigma \tau =\begin{pmatrix}
			1 &2  &3  &4   \\
			 1&4  &3  &2   \\
		\end{pmatrix}
	\]
	and
	\[
		\tau \sigma =\begin{pmatrix}
			1 &2  &3  &4   \\
			 3&2  &1  &4   \\
		\end{pmatrix}
	\]
\end{eg}
\subsection*{Cycle Notation}
\begin{definition}[Permutations as Cycles]
	A permutation \(\sigma \in S_X\) is a \textbf{cycle} \textbf{of} \textbf{length} \(k\) if there exists \(a_1,\ldots,a_k\in X\) such that
	\newpage\[
		\sigma \left( a_1 \right) =a_2
	\]
	\[
		\sigma \left( a_2 \right) =a_3
	\]
	\[
		\vdots
	\]
	\[
		\sigma \left( a_k \right) =a_1
	\]
	and \(\sigma (x)=x\) for all other \(x\in X\). We write \((a_1,\ldots,a_k)\) to denote the cycle \(\sigma \).
\end{definition}
\begin{remark}
	Cycles are the building blocks of all permutations.
\end{remark}
For example, the permutation 
\[
	\sigma =\begin{pmatrix}
		1 &2  &3  &4  &5  &6  &7   \\
		 6&3  &5  &1  &4  &2  &7   \\
	\end{pmatrix}=(162354)
\]
is a cycle of length 6, and 
\[
	\tau =\begin{pmatrix}
		1 &2  &3  &4  &5  &6   \\
		 1&4  &2  &3  &5  &6   \\
	\end{pmatrix}=(243)
\]
is a cycle of length 3. Not all permutations are cycles. For example,
\[
	\mu =\begin{pmatrix}
		1 &2  &3  &4  &5  &6   \\
		 2&4  &1  &3  &6  &5   \\
	\end{pmatrix}=(1243)(56)
\]
coinsists of both a cycle of length 2 and of length 4. 
\begin{eg}
	It's easy to compute compositions of cycles. Let 
	\[
		\sigma =(1352)\text{ and } \tau =(256)
	\]
	We can think of \(\sigma \) as 
	\[
		\sigma \equiv \left\{\begin{array}{c}
			1\mapsto 3\\
			3\mapsto 5\\
			5\mapsto 2\\
			2\mapsto 1
		\end{array}\right.
	\]
	and we can think of \(\tau \) as 
	\[
		\tau \equiv \left\{\begin{array}{c}
			2\mapsto 5\\
			5\mapsto 6\\
			6\mapsto 2
		\end{array}\right.
	\]
	Thus, we can find
	\[
		(\sigma \circ \tau )\equiv \left\{\begin{array}{c}
			2\mapsto 5\mapsto 2\\
			5\mapsto 6\\
			6\mapsto 2\mapsto 1\\
			1\mapsto 3\\
			3\mapsto 5\\
			5\mapsto 2\mapsto 5
		\end{array}\right.\equiv \left\{\begin{array}{c}
			5\mapsto 6\\
			6\mapsto 1\\
			1\mapsto 3\\
			3\mapsto 5
		\end{array}\right.\equiv (1356)
	\]
	Similarly, if \(\mu =(1634)\), then \(\sigma \mu =(1652)(34)\) 
\end{eg}
\begin{definition}[Disjoint Cycles]
	If \(\sigma ,\tau \in S_X\) are cycles such that \(\sigma =(a_1,\ldots,a_k)\) and \(\tau =(b_1,\ldots,b_l)\), then \(\sigma \) and \(\tau \) are \textbf{disjoint} if \(a_i \neq b_j\) for all \(i,j\).
\end{definition}
The products of disjoint cycles cannot be simplified.
\begin{proposition}
	Let \(\sigma \) and \(\tau \) be disjoint cycles in \(S_X\). \(\sigma \tau =\tau \sigma \).
\end{proposition}
\begin{proof}
	Let \(\sigma =(a_1,\ldots,a_k)\) and \(\tau =(b_1,\ldots,b_l)\). We must show \(\sigma \tau (x)=\tau \sigma (x)\) for all \(x\in X\). If \(x\notin \{ a_1,\ldots,a_k \} \) and \(x \notin \{ b_1,\ldots,b_l \} \), then both \(\sigma \) and \(\tau \) \textbf{fix} \(x\), meaning \(\sigma (x)=x\) and \(\tau (x)=x\). Thus,
	\[
		\sigma \tau (x)=\sigma (\tau (x))=\sigma (x)=x=\tau (x)=\tau (\sigma (x))=\tau \sigma (x)
	\]
	Now, suppose \(x\in {a_1,\ldots,a_k}\). Thus, \(\sigma (a_i)=a_{(i\mod k)+1} \), meaning 
	\begin{align*}
		a_1&\mapsto a_2\\
		a_2&\mapsto a_3\\
		&\vdots\\
		a_{k-1}&\mapsto a_k\\
		a_k&\mapsto a_1 
	\end{align*}
	Since \(\sigma \) and \(\tau \) are disjoint, then \(\tau (a_i)=a_i\). Thus, 
	\begin{align*}
		\sigma \tau (a_i)&=\sigma (\tau (a_i))\\
		&=\sigma (a_i)\\
		&=a_{(i\mod k)+1}\\
		&=\tau (a_{(i\mod k)+1})\\
		&=\tau (\sigma (a_{i} ))\\
		&=\tau \sigma (a_i)
	\end{align*}
	The same logic holds for \(x\in\{ b_1,\ldots,b_l  \} \). Since \(\sigma \) and \(\tau \) are disjoint,
	\[
		\{ a_1,\ldots,a_k \} \cap \{ b_1,\ldots,b_l \} =\varnothing 
	\]
\end{proof}
\begin{theorem}[Permutations as Cycles]
	Every permutation \(\sigma \in S_n\) can be written as the product of disjoint cycles.
\end{theorem}
\begin{proof}
	Assume \(X=\{1,2,\ldots,n\}\). Let \(\sigma \in S_n\) and define \(X_1=\{ \sigma (1),\sigma^2 (1),\ldots \} \). The set \(X_1\) must be finite, since the set \(X\) is finite. Let \(i\in\mathbb{Z} \) be the first integer in \(X\) that is not in \(X_1\), and let \(X_2=\{ \sigma (i),\sigma ^2(i),\ldots \} \). Again, this set is finite. Now we can define \(X_3,X_4,\ldots\) in the same manner. Since \(X\) is finite, there will be a finite number of these \textbf{disjoint} sets. Let this number be \(r\). If \(\sigma _i\) is given as 
	\[
		\left\{\begin{array}{cc}
			\sigma (x)&x\in X_i\\
			x&x\notin X_i
		\end{array}\right.
	\]
	Then \(\sigma =\sigma _1 \sigma _2 \cdots \sigma _r\). Since the sets \(X_1,\ldots, X_r\) are disjoint, then the cycles \(\sigma _1,\ldots,\sigma _r\) are also disjoint.
\end{proof}
\begin{remark}
	Permutations will generally be represented by cycles for brevity, and the identity permutation will be given as \((1)\).
\end{remark}
\subsection*{Transpositions}
\begin{definition}[Transposition]
	A transposition is a cycle of length 2.
\end{definition}
\begin{proposition}
	Any permutation of a finite set containing at least two elements can be given as the product of transpositions.
\end{proposition}
\begin{eg}
	For example, the permutation
	\[
		(16)(253)=(16)(23)(25)
	\]
\end{eg}
There is no unique representation of permutations as a product of transpositions. For example, the above permutation can also be given as
\[
	(16)(45)(23)(45)(25)
\]
Interestingly, no permutation can be written as both an odd \emph{and} an even number of transpositions. 
\begin{lemma}\label{lma:11}
	If the identity is written as the product of \(r\) transpositions 
	\[
		\text{id}=\tau _1 \tau _2 \cdots \tau _r 
	\]
	then \(r\) is even.
\end{lemma}
\begin{theorem}
	If a permutation \(\sigma \) can be expressed as the product of an even number of transpositions, then all other products of transpositions equaling \(\sigma \) must contain an even number of transpositions. Similarly, if \(\sigma \) can be expressed as an odd number of transpositions, then any set of transpositions equaling \(\sigma \) must be odd.
\end{theorem}
\begin{proof}
	Suppose 
	\[
		\sigma =\sigma _1 \sigma _2\cdots \sigma _m =\tau _1 \tau _2 \cdots \tau _n
	\]
	where \(m\) is even. The inverse of \(\sigma \) is \(\sigma _m \cdots \sigma _1\).
	\[
		\text{id} =\sigma \sigma _m \cdots \sigma _1=\tau _1\cdots \tau _n \sigma _m\cdots \sigma _1
	\]
thus \(n\) is even by \ref{lma:11}.
\end{proof}
We say a permutation is \textbf{even} if it can be expressed as an even number of transpositions, and \textbf{odd} if it requires an odd number.
\subsection*{The Alternating Groups}
An important subgroup of \(S_n\) is \(A_n\), the set of all even permutations. We say \(A_n\) is the \textbf{alternating} \textbf{group} \textbf{on} \(n\) \textbf{letters}.
\begin{theorem}
	The set \(A_n\) is a subgroup of \(S_n\).
\end{theorem}
\begin{proof}
	Since the product of any two even transpositions will be even, \(A_n\) is closed. By \ref{lma:11}, \(\text{id}\in A_n \). Let \(\sigma \in A_n\) be an even permutation. Since it's even, there must exist transpositions \(\sigma _1,\ldots,\sigma _r\) such that 
	\[
		\sigma = \sigma _1,\cdots,\sigma _r
	\]
	where \(n\) is even. Since the inverse of a transposition is itself, it follows that 
	\[
		\sigma ^{-1} = \sigma _r \cdots \sigma_1
	\]
	It follows that \(\sigma ^{-1} \in A_n\).
\end{proof}
\begin{proposition}
	The number of even permutations in \(S_n\) with \(n\geq 2\) is equal to the number of odd permutations, and thus \(\vert A_n \vert =\frac{n!}{2} \).
\end{proposition}
\begin{proof}
	Let \(A_n\) and \(B_n\) be the sets of even and odd permutations in \(S_n\), respectively. If there exists some bijection between these sets, then \(\vert A_n \vert = \vert B_n \vert  \). Let \(\sigma \in S_n\) be a transposition. Such a \(\sigma \) exists because \(n\geq 2\). Define 
	\[
		\lambda _\sigma :A_n \to B_n
	\]
	as the mapping 
	\[
		\lambda _\sigma (\tau )=\sigma \tau 
	\]
	We must show \(\lambda _\sigma \) is bijective. First we show it's injective. Let \(\tau ,\mu \in A_n\) with \(\lambda _\sigma (\tau )=\lambda _\sigma (\mu )\). We must show this implies \(\tau =\mu \). It follows that
	\[
		\sigma \tau =\sigma \mu 
	\]
	\[
		\Longrightarrow \tau =\sigma ^{-1} \sigma \tau =\sigma ^{-1} \sigma \mu =\mu 
	\]
	\[
		\therefore \tau =\mu 
	\]
	We must now show \(\lambda _\sigma \) is surjective. It suffices to show that for any \(\tau \in B_n\), there exists some \(\mu \in A_n\) such that \(\lambda _\sigma (\mu )=\tau \). Let \(\tau \in B_n\). It follows that there exists some set of transpositions \(\left\{ \tau _1,\ldots,\tau _m \right\} \) with \(m\) being odd, such that 
	\[
		\tau =\tau _1 \cdots \tau _m
	\]
	Let \(\mu \coloneqq \sigma ^{-1} \tau _1 \cdots \tau _m = \sigma ^{-1} \tau \) 
	This is still an element of \(S_n\) since \(S_n\) is a group, but is no longer an element of \(B_n\) since it is obviously composed of an even number of transpositions. Thus, \(\mu \in A_n\). As such, we can consider 
	\[
		\lambda _\sigma (\mu )= \sigma \sigma ^{-1} \tau = \tau 
	\]
	Therefore, such a \(\mu \) always exists since \(S_n\) is closed under function composition. Therefore, 
	\[
		\left\vert A_n \right\vert = \left\vert B_n \right\vert
	\]
\end{proof}
\section{Dihedral Groups}
A special type of permutation group is the dihedral group. We define the \textbf{nth} \textbf{dihedral} \textbf{group} to be the group of rigid motions of a regular \(n\)-gon, denoted \(D_n\).
\begin{theorem}
	The dihedral group, \(D_n\), is a subgroup of \(S_n\) of order \(2n\).
\end{theorem}
This theorem comes from the fact that since the \(n\)-gon is rigid, if we denote the vertices of the \(n\)-gon in order by \(1,2,\ldots,n\), we will find that if the vertex \(1\) is replaced with some \(k\), then the next vertex can only be \(k-1\) or \(k+1\). This gives rise to \(2n\) different orientations of the \(n\)-gon, which can be thought of as two sets of order \(n\) but with a negative sign flipped.
\begin{theorem}
	The group \(D_n\) for \(n\geq 3\) consists of all products of two elements \(r\) and \(s\), where \(r\) has order \(n\) and \(s\) has order \(2\), and \(srs=r^{-1} \).
\end{theorem}
\begin{proof}
	The possible motions of some \(n\)-gon consist of rotations and reflections. There are obviously exactly \(n\) possible rotations, which can be generated by a rotation of only one vertex. We denote this rotation \(r\) as the permutation that rotates by
	\[
		\frac{360^{\circ } }{n}
	\]
	and find that all other rotations \(r^k\) can be represented as \(k\) repeated applications of \(r\). Thus, \(r\) has order \(n\). Now define \(s_1,\ldots,s_n\) where \(s_k\) is the reflection that fixes vertex \(k\). Two repeated rotations will fix all vertexes, so the order of any \(s_k\) is two. Let \(s=s_1\). We have \(s^2 =1\) and \(r^n =1\). Any rigid motion \(1\mapsto k\) must replace the next vertex by either \(k+1\) or \(k-1\). If it's replaced by \(k+1\), then the motion is given by \(r^k\). If its replaced by \(k-1\), its given by \(r^k s\). Therefore, \(\{ r,s \} \) generates \(D_n\). 
\end{proof}
\chapter{Cosets and Lagrange's Theorem}
Lagrange's theorem is important in finite group theory, but understanding it relies heavily on the notion of a coset. 
\section{Cosets}
\begin{definition}[Cosets]
	Let \(G\) be a group with a subgroup \(H\) and some \(g\in G\). The \textbf{left} \textbf{coset} of \(H\) with representative \(g\) is the set
	\[
		gH = \left\{ gh \mid h\in H \right\} 
\]
Similarly, the \textbf{right} \textbf{coset} of \(H\) with representative \(g\) is the set
\[
	Hg = \left\{ hg \mid h\in H \right\} 
\]
\end{definition}
If left and right cosets are the same or it's obvious which coset is being referenced, often these sets are referenced simply as cosets without specification as to the side.
\begin{proposition}
	Left and right cosets in an abelian group are always identical.
\end{proposition}
\begin{lemma}\label{lma:6.3}
	Let \(H\) be a subgroup of \(G\) and let \(g_1,g_2\in G\). The following conditions are equivalent.
	\begin{itemize}
		\item \(g_1 H=g_2 H\)
		\item \(H g^{-1} _1=H g^{-1} _2\)
		\item \(g_1 H \subset g_2 H\)
		\item \(g_2\in g_1 H\)
		\item \(g^{-1} _1 g_2 \in H\)
	\end{itemize}
\end{lemma}
\begin{proof}
	Proof not provided, I will do this when im not exhausted i think
\end{proof}
\begin{theorem}\label{cospart}
	Let \(H\) be a subgroup of some group \(H\). The left cosets of \(H\) in \(G\) partition \(G\).
\end{theorem}
\begin{proof}
	Let \(g_1,g_2\in G\) and \(g_1 H\), \(g_2 H\) be left cosets of \(H\) in \(G\). We must show that \(g_1 H \cap g_2 H = \varnothing \) or \(g_1 H = g_2 H\). Suppose \(g_1 H \cap g_2 H \neq \varnothing \). It follows that there exists some \(a\in g_1 H \cap g_2 H\). By definition of a left coset, \(a=g_1 h_1 = g_2 h_2\) for some \(h_1,h_2\in H\). Thus, \(g_1 =g_2 h_2 h^{-1} _1\). Since \(H\) is a subgroup, \(h^{-1} _1\in H\) and \(h_2 h^{-1} _1 \in H\). Therefore, \(g_2 h_2 h^{-1} _1 \in g_2 H\). This implies \(g_1\in g_2 H\). By lemma \ref{lma:6.3}, \(g_1 H = g_2 H\). Therefore, \(g_1 H\cap g_2 H \neq \varnothing \Longrightarrow g_1 H = g_2 H \).
\end{proof}
There is nothing special in this proof for left cosets, so we can define an equivalent statement for right cosets of \(H\) in \(G\).
\begin{definition}[Index]\label{indx}
	Let \(G\) be a group with subgroup \(H\). Define the \textbf{index} of \(H\) in \(G\) to be the number of left cosets of \(H\) in \(G\), denoted \([G:H]\).
\end{definition}
\begin{theorem}
	Let \(H\) be a subgroup in \(G\). The number of left cosets of \(H\) in \(G\) is the same as the number of right cosets of \(H\) in \(G\).
\end{theorem}
\begin{proof}
	Let \(\mathcal{R} _H\) and \(\mathcal{L} _H\) be the sets of right and left cosets of \(H\), respecitvely. We must define a bijection \(\phi :\mathcal{L} _H \to \mathcal{R} _H\). Let \(gH\in \mathcal{L}_H\), and define \(\phi (gH)=Hg^{-1} \). Lemma \ref{lma:6.3} states that if \(g_1 H = g_2 H\), then \(H g^{-1} _1 = H g^{-1} _2\). This shows that no \(\phi (gH)\) can map to multiple values, and thus \(\phi \) is well defined. Furthermore, for any \(Hg\in \mathcal{R} _H\), there exists some \(g^{-1} H\in \mathcal{L} _H\) such that \(\phi \left( g^{-1} H \right)=H (g^{-1}) ^{-1} =Hg \). Such an inverse exists because \(g\in G\) and \(G\) is a group. Therefore \(\phi \) is surjective. Now show that \(\phi \) is injective. Suppose \(\phi (g_1 H)=\phi (g_2 H)\). By definition, \(H g^{-1} _1 =H g^{-1} _2\). From lemma \ref{lma:6.3}, this implies that \(g_1 H = g_2 H\). Therefore \(\phi \) is bijective, and
	\[
		\left\vert \mathcal{L} _H \right\vert = \left\vert \mathcal{R} _H \right\vert 
	\]
\end{proof}
\section{Lagrange's Theorem}
\begin{proposition}\label{prowo}
	Let \(H\) be a subgroup of \(G\) with \(g\in G\) and define the map \(\phi :H\to gH\) by \(\phi (h)=gh\). \(\phi \) is bijective, and thus \(\vert H \vert=\vert gH \vert  \).
\end{proposition}
\begin{proof}
	To show \(\phi \) is injective, let \(h_1,h_2\in H\) with \(h_1 =h_2\). We must show that this implies \(\phi (h_1)=\phi (h_2)\). Notice that \(\phi (h_1)=gh_1\) and \(\phi (h_2)=gh_2\). Thus we have
	\[
		\phi (h_1)h^{-1}_1 =gh_1 h_1 ^{-1} =g
	\]
	\[
		\phi (h_2)h^{-1} _2 = gh_2 h_2 ^{-1} =g
	\]
	However, inverses are unique, so \(h_1 = h_2 \Longrightarrow h_1 ^{-1} =h_2 ^{-1} \). Therefore, we have
	\begin{align*}
		&\qquad \phi (h_2)h_2 ^{-1} = \phi (h_2)h_1 ^{-1}\\
		&\Longrightarrow \phi (h_1)h_1 ^{-1} =\phi (h_2) h_1 ^{-1} \\
		&\Longrightarrow \phi (h_1)=\phi (h_2)
	\end{align*}
	Therefore, \(\phi \) is injective. Now we must show that \(\phi \) is surjective by showing that for any \(\alpha \in gH\), there exists a corresponding \(h\in H\) such that \(\phi (h)=\alpha \). To do this, start by recognizing that \(\alpha \) can be written as some \(gh\), and that \(\phi \) by definition maps \(h\mapsto gh\). Therefore, for any \(gh\in gH\), simply notice that \(h\in H\) has \(\phi (h)=gh\). Therefore, \(\phi \) is bijective.
\end{proof}
\begin{theorem}[Lagrange's Theorem]
	Let \(G\) be a finite group with subgroup \(H\). Then \(\vert G \vert /\vert H \vert = [G:H]  \) is the number of distinct left cosets of \(H\) in \(G\). The number of elements in \(H\) must divide the number of elements in \(G\).
\end{theorem}
\begin{proof}
	By \ref{cospart} and via \ref{indx}, \(G\) is partitioned into \([G:H]\) distinct left cosets. By \ref{prowo}, each coset has \(\vert H \vert \) elements. Since each coset is distinct from the rest, the total number of cosets times the order of each coset will give the order of \(G\). Thus, \(\vert G \vert=[G:H]\vert H \vert  \).
\end{proof}
\begin{corollary}\label{cor6.1}
	Suppose \(G\) is a finite group with \(g\in G\). Then the order of \(g\) must divide \(\vert G \vert \).
\end{corollary}
\begin{corollary}\label{cor6.2}
	Let \(\vert G \vert =p\) with \(p\) as a prime number. Then \(G\) is cyclic and any \(g\in G\) with \(g\neq e\) will be a generator.
\end{corollary}
\begin{proof}
	Let \(g\in G\) with \(g\neq e\). Recall that the order of an element is the number of operations required to return to that original element. Since identities are unique, \(\vert \langle g \rangle   \vert\neq 1 \), and thus \(\vert \langle g \rangle  \vert =p \) since \(p\) is prime and \(\vert \langle g \rangle  \vert \) must divide \(p\) by \ref{cor6.1}. Thus, \(\langle g \rangle =G \).
\end{proof}
\begin{remark}
	The converse of Lagrange's theorem is false. Just because a group can have subgroups of some order does not mean those subgroups actually exist. Proof of this is noted by the next proposition.
\end{remark}
\begin{proposition}
	The group \(A_4\) has no subgroups of order \(6\).
\end{proposition}
\begin{proof}
	Recall from Chapter 5 that \(A_4\) is the set of all even permutations in \(S_4\), and 
	\[
		\left\vert A_4 \right\vert = \frac{4!}{2}=12
	\]
	Let \(\vert H \vert =6\) and note that \([G:H]=\vert G \vert/ \vert H \vert =2  \). Since one of the cosets is formed by \(eH=H\), there must exist some other element \(g\in A_4\) with \(gH \neq H\). Specifically, \(gH=G\setminus H\), since \(gH\) is what's ``left over'' from the other coset. However, \(He=H\) is also a right coset, and the same logic shows that \(Hg=G\setminus H\). Therefore, \(gH=Hg\). This implies that \(gHg^{-1} =Hgg^{-1} =H\). This means that for any \(g\in G\), \(gH=Hg\), since this holds for both \(gH=H\) or \(gH\neq H\). This shows that for any \(g\in H\), \(ghg^{-1} \in H\) for some \(h\in H\) by the previous logic. Since there are eight cycles of order 3 in \(A_4\), there will exist at least one in \(H\). WLOG, let \((123)\in H\). Then \((123)^{-1} =(132) \in H\). Since \((124),(243)\in A_4\) with inverses \((142),(234)\in A_4\), respectively, we have 
	\[
		(124)(123)(124)^{-1} =(124)(123)(142)=(324)=(243)
	\]
	Therefore \((243)\in H\), and thus \((243)^{-1} =(234)\in H\). We now have defined 4 elements of \(H\).
	\[
		(243)(123)(243)^{-1} =(243)(123)(234)=(142)
	\]
	Therefore \((142)\in H\), and thus \((142)^{-1} =(124)\in H\). We have now defined \(6\) elements of \(H\), which is the maximum our assumption allowed for. Now notice that \((1)\in H\), which brings the total to 7. Therefore there exists no such \(H\) with 6 elements, and \(A_4\) has no subgroup of order 6.
\end{proof}
\begin{theorem}
	Two cycles \(\tau ,\mu \in S_n\) have the same order if and only if there exists some \(\sigma \in S_n\) such that \(\mu =\sigma \tau \sigma ^{-1} \).
\end{theorem}
\begin{proof}
	Let
	\[
		\tau =\left( a_1,\ldots,a_k \right) 
	\]
	\[
		\mu =\left( b_1,\ldots,b_k \right) 
	\]
	Define \(\sigma (a_i)=b_i\) for some index \(i\in\mathbb{N}\). For any \(b_{i} \), observe that 
	\[
		\sigma ^{-1} (b_i)=a_i
	\]
	\[
		\mu a_i = a_{i+1} 
	\]
	\[
		\sigma (a_{i+1} )=b_{i+1} 
	\]
	\[
		\mu (b_i)=b_{i+1} 
	\]
	where addition in the index is defined to be \((i\,\,\text{mod }k )+1\). Therefore, \(\mu =\sigma \tau \sigma ^{-1} \).\\
	For the reverse case, let \(\tau \) retain the above definition and let \(\sigma \in S_n\) be arbitrarily chosen such that \(\sigma \tau \sigma ^{-1} =\mu \). If \(\sigma (a_i)=b\) and \(\sigma \left( a_{(i\,\,\text{mod }k )+1} \right)=b^{\prime}  \), then \(\mu (b)=b^{\prime} \). Since \(\sigma \) is bijective, the cycle 
	\[
		\mu =\left( \sigma (a_1),\sigma (a_2),\ldots,\sigma (a_k) \right) 
	\]
	is the same length as \(^\tau \).
\end{proof}
\section{Fermat's and Euler's Theorems}
The Euler \(\phi \)-Function is the map \(\phi :\mathbb{N}\to \mathbb{N}\) defined as \(\phi (1)=1\) and \(\phi (n)\) as the number of integers that are coprime to \(n\) (\(\operatorname{gcd}(m,n)=1 \) for \(1\leq m<n\)), for \(n>1\).
\begin{theorem}\label{protogen}
	Let \(U(n)\) be the group of units in \(\mathbb{Z}_n\). Then \(\vert U_n \vert =\phi (n)\).
\end{theorem}
This gives rise to an important theorem in number theory.
\begin{theorem}[Euler's Theorem (wow great name guys)]
	Let \(a,n\in\mathbb{Z}\) with \(n>0\) and \(\operatorname{gcd}(a,n)=1 \). Then \(a^{\phi (n)} \equiv 1\,\,(\text{mod }n )\).
\end{theorem}
\begin{proof}
	By \ref{protogen}, \(\vert U(n) \vert=\phi (n) \). Therefore, either \(a^{\phi (n)}=1\) for all \(a\in U(n)\), or \(a^{\phi (n)}-1\) is divisible by \(n\). Therefore, \(a^{\phi (n)} \equiv 1\,\,(\text{mod }n )\).
\end{proof}
Notice that, trivially, \(\phi (p)=p-1\) for any prime number. This leads to the special case known as Fermat's Little Theorem, not to be confused with Fermat's Last Theorem.
\begin{theorem}[Fermat's Little Theorem]
	Let \(p\) be prime and suppose \(p\nmid a\). Then 
	\[
		a^{p-1}\equiv 1\,\,(\text{mod } p)
	\]
	Furthermore, for any \(b\in\mathbb{Z}\), \(b^p \equiv b\,\,(\text{mod }p )\).
\end{theorem}
\chapter{Isomorphisms}
(skipping chapters 7 and 8 because i dont find those applications of algebra very interesting, and since I have to take a class on algebra in college anyways id prefer to read what I find \textbf{enjoyable} rather than everything in the textbook).
\section{Definition and Examples}
\begin{definition}[Group Isomorphism]
	Two groups \((G,\cdot)\) and \((H,\circ )\) are \textbf{isomorphic} if there exists a bijective map \(\phi :G\to H\) that preserves the group operation. That is,
\[
	\phi (a\cdot b)=\phi (a)\circ \phi (b)
\]
for all \(a,b\in G\). If \(G\) is isomorphic to \(H\), we write \(G\cong H\) and call \(\phi \) an isomorphism, specifically a \textbf{group} \textbf{isomorphism}.
\end{definition}
\begin{eg}
	We can show that \(\mathbb{Z}_{4}\cong \langle i \rangle  \). Define \(\phi :\mathbb{Z}_4 \to \langle i \rangle \) as the map \(\phi (n)=i^{n} \). The reasons for such a definition should be self-evident. Brute force can show that \(\phi \) is bijective:
	\begin{align*}
		\phi (0)=1&&\phi (1)=i\\
		\phi (2)=-1&&\phi (3)=-i
	\end{align*}
	To show that \(\phi \) preserves the group operation, let \(m,n\in \mathbb{Z}_4\). We have
	\[
		\phi (m+n)=i^{m+n}=i^m i^n = \phi (m)\phi (n)
	\]
	Therefore the group operation is preserved, and \(\mathbb{Z}_4 \cong \langle i \rangle \).
\end{eg}
\begin{eg}
	The groups \(\mathbb{Z}_8\) and \(\mathbb{Z}_{12} \) cannot be isomorphic, since \(\vert \mathbb{Z}_8 \vert \neq \vert \mathbb{Z}_{12}  \vert  \).
\end{eg}
\begin{theorem}\label{isowowo}
	Let \(\phi :H\to G\) be a group isomorphism. Then the following is true. 
	\begin{itemize}
		\item \(\phi ^{-1} :H\to G\) is an isomorphism. 
		\item \(\vert G \vert =\vert H \vert  \)
		\item If \(G\) is abelian, then \(H\) is abelian.
		\item If \(G\) is cyclic, then \(H\) is cyclic.
		\item If \(G\) has a subgroup of order \(n\), then \(H\) has a subgroup of order \(n\).
	\end{itemize}
\end{theorem}
\begin{proof}
	The first two follow from the fact that \(\phi \) is a bijection. The proofs of 4 and 5 are left as an exercise, so this should be fun.\\
	Let \(h_1,h_2\in H\). Since \(\phi \) is surjective, there exist \(g_1,g_2\in G\) such that \(\phi (g_1)=h_1\) and \(\phi (g_2)=h_2\). Let \(G\) be abelian. Therefore,
	\begin{align*}
		h_1 h_2 &= \phi (g_1)\phi (g_2)\\
		&=\phi (g_1 g_2)\\
		&=\phi (g_2 g_2)\\
		&=\phi (g_2)\phi (g_1)\\
		&=h_2 h_1
	\end{align*}
	To prove the fourth statement, notice that
	\[
		\phi \left( n^k \right) =\phi (n\cdots n)=\phi (n)\cdots \phi (n)=\phi (n)^k
	\]
	for some \(k\in\mathbb{Z}\). Let \(G\) be cyclic with \(\langle g \rangle =G \) for some generator \(g\in G\). Let \(\phi (g)=h\). Since \(g\) generates \(G\), any \(g^{\prime} \in G\) can be written as
	\[
		g^k = g^{\prime} 
	\]
	for some \(k\in\mathbb{Z}\). Therefore, for all \(g^{\prime} \in G\), we have 
	\[
		\phi \left( g^{\prime}  \right) =\phi \left( g^k \right) =\phi (g)^k = h^k
	\]
	Since \(\phi \) is bijective, any \(h^{\prime} \) can be written as some \(\phi \left( g^{\prime}  \right) \), implying that any \(h^{\prime} \) can thus be written as some \(\phi \left( g^k \right)=h^k\). Therefore, \(H\) is cyclic and \(\langle h \rangle=H \).\\
	Now we show the fifth condition. Let \(S\) be a subgroup of \(G\) with \(\vert S \vert =n \). We can define the set \(L\) as the set 
	\[
		L\coloneqq \left\{ \phi (s) \mid s\in S \right\} 
	\]
	If we let \(s_1,s_2\in S\), then \(s_1 s_2 \in S\). Furthermore, \(\phi (s_1 s_2)=\phi (s_1)\phi (s_2)\), and \(\phi (s_1),\phi (s_2)\in L\). However, since \(s_1 s_2\in S\), \(\phi (s_1 s_2)\in L\), and thus \(\phi (s_1)\phi (s_2)\in L\). Therefore, \(L\) is closed under the group operation, and defines a subgroup of \(H\). Because \(\phi \) is a bijection and we can abuse notation to concisely say \(\phi (S)=L\), \(\vert S \vert=\vert L \vert  =n\).
\end{proof}
\begin{theorem}
	All cyclic groups of infinite order are isomorphic to \(\mathbb{Z}\).
\end{theorem}
\begin{proof}
	Let \(G\) be a cyclic group with infinite order and let \(\langle a \rangle =G \) be a generator for \(G\). Define the map \(\phi :\mathbb{Z}\to G\) by \(n\mapsto a^n\). Then 
	\[
		\phi (m+n)=a^{m+n}=a^m a^n = \phi (m)\phi (n)
	\]
	Now we must show \(\phi \) is a bijection. Let \(m,n\in \mathbb{Z}\) with \(m\neq n\), specifically WLOG \(m>n\). Suppose for purpose of contradiction that \(a^m = a^n\). It follows that 
	\[
		a^{m-n}=e \Longrightarrow \Longleftarrow 
	\]
	because this contradicts the assumption that \(G\) has infinite order, and \(m-n>0\) is finite. Since \(a\) is a generator for \(G\), \(\phi \) is onto since for any \(\alpha \in G\), there exists some integer \(n\) such that \(\alpha =a^n\), and \(\phi (n)=a^n = \alpha \). Therefore, \(\phi \) is an isomorphism.
\end{proof}
\begin{theorem}\label{iwi}
	Let \(G\) be cyclic with \(\vert G \vert=n \). Then \(G\cong \mathbb{Z}_n\).
\end{theorem}
\begin{proof}
	Let \(G\) be a cyclic group with order \(n\) and generator \(a\in G\). Define the map \(\phi :\mathbb{Z}_n \to G\) by \(k\mapsto a^k\), with \(0\leq k<n\). The proof that \(\phi \) is an isomorphism is left as an exercise wooooooooo\\
	First, show that \(\phi \) preserves the group operation. Let \(m,r\in \mathbb{Z}_n\). Notice that \(m,r<n\) in \(\mathbb{Z}_n\). Thus,
	\[
		\phi (m+r)=a^{m+r}=a^m a^r = \phi (m)\phi (r)
	\]
	Now it remains to be shown that \(\phi \) is a bijection. Suppose \(m\neq r\). WLOG, let \(m>r\). Suppose for purpose of contradiction that \(\phi (m)=\phi (r)\). We have
	\[
		\phi (m) = \phi (r) \Longrightarrow a^m = a^r \Longrightarrow a^{m-r}=e
	\]
	\[
		m>r\Longrightarrow m-r\neq \alpha n\,\forall \alpha \in\mathbb{Z} \Longrightarrow \Longleftarrow
	\]
	Therefore \(m\neq r \Longrightarrow \phi (m)\neq \phi (r)\). It remains only to be shown that \(\phi \) is surjective. Any \(g\in G\) can be written as \(a^k\) for some \(0\leq k<n\). Notice that 
	\[
		g =a^k = \phi (k)
	\]
	Therefore \(\phi \) is surjective, and \(\therefore G\cong \mathbb{Z}_n\).
\end{proof}
\begin{corollary}
	If \(G\) is a group of order \(p\) with \(p\) as a prime number, then \(G\cong \mathbb{Z}_p\).
\end{corollary}
\begin{proof}
	By \ref{cor6.2}, any \(\vert G \vert =p \) is cyclic. Thus, by \ref{iwi}, \(G\cong \mathbb{Z}_p\).
\end{proof}
\begin{theorem}
	Isomorphisms of groups defines an equivalence relation on the class of all groups.
\end{theorem}
\begin{proof}
	Proof is left as an exercise. Luckily I thought of this about a month ago and already proved it!!!\\
	Any group is trivially isomorphic to itself by the identity function. Thus, \(G\cong G\) for some group \(G\). Let \(G\) and \(H\) be groups with isomorphism \(\phi :G\to H\). By \ref{isowowo}, \(\phi ^{-1} :H\to G\) is also an isomorphism, so \(G\cong H \Longrightarrow H\cong G\). Now let \(\phi:G\to H \) define the isomorphism \(G\cong H\) and let \(\psi:H\to I \) define the isomorphism \(H\cong I\), where \(I\) is a group. Consider the function \(\psi \circ \phi :G\to I\). Let \(g_1,g_2\in G\). Since \(\phi \) and \(\psi \) are isomorphisms, we have 
	\[
		(\psi \circ \phi )(g_1 g_2)=\psi (\phi (g_1 g_2))=\psi (\phi (g_1)\phi (g_2))=\psi (\phi (g_1))\psi (\phi (g_2))=(\psi \circ \phi )(g_1)(\psi \circ \phi )(g_2)
	\]
	Therefore \(\psi \circ \phi \) is an isomorphism, and \(G\cong H \land H\cong I \Longrightarrow G\cong I\). Therefore, isomorphisms define an equivalence relation on the class of groups.
\end{proof}
The result of this theorem gives a goal of group theory: to classify all groups up to isomorphism with groups that are well studied, since we can treat isomorphic groups as equivalent. This idea gives rise to representation theory, where we represent groups with isomorphic groups we know a lot about. The following theorem is a representation theorem, and a very strong one at that.
\begin{theorem}[Cayley]
	Every group is isomorphic to a group of permutations.
\end{theorem}
\begin{longproof}
	Let \(G\) be a group. The goal is to find some group of permutations \(\overline{G} \) that is isomorphic to \(G\). For any \(g\in G\), define a function \(\lambda _g :G\to G\) as \(\lambda _g(a)=ga\). We must show each \(\lambda_g\) defines a permutation on \(G\). To show that it is one to one, let \(\lambda _g(a)=\lambda _g(b)\) and notice that 
	\[
		\lambda _g(a)=ga
	\]
	\[
		\lambda _g(b)=gb
	\]
	\[
		\Longrightarrow gb=gb \Longrightarrow g=a
	\]
	Therefore \(\lambda _g\) is injective. To show that it is surjective, we must show for any \(a\in G\), there exists some \(b\in G\) such that \(\lambda _g(b)=a\). Let \(b=g^{-1} a\). We have \(\lambda _g(b)=a\).\\
	Now we can define the group \(\overline{G} \):
	\[
		\overline{G} \coloneqq \left\{ \lambda _g \mid g\in G \right\}
	\]
	It still remains to be shown that \(\overline{G} \) is both a group and that it is isomorphic to \(G\). To show this first thing, since it is more important, we suppose that \(\left( \overline{G} ,\circ  \right) \) is a group. Let \(g,h,k,a\in G\)and consider closure under addition. 
	\[
		(\lambda _g \circ \lambda _h)(a)=\lambda _g \left( \lambda _h (a) \right) =\lambda _g (ha)=gha = \lambda_{gh}(a) 
	\]
	Since \(G\) is a group, \(gh\in G\), and thus \(\lambda_{gh}\in \overline{G}  \). Next, we show associativity. 
	\[
		\left( \lambda _g \circ \left( \lambda _h \circ \lambda_k \right)  \right)(a)= \lambda_g \left(\left(\lambda _h \circ \lambda_k\right)(a)\right)=\lambda _g \left( \lambda _h \left( \lambda _k (a) \right) \right) = \left( \lambda _g \circ \lambda _h \right) \left( \lambda _k(a) \right)
	\]
	\[
		=\left( \left( \lambda _g \circ \lambda _h \right)\circ \lambda _k  \right) (a)
	\]
	Therefore \(\overline{G} \) is associative. Notice that \(\lambda_e (a)=ea=a\), meaning \(\lambda_e = \text{id}_G \). As seen previously, this is an additive identity under function composition. Define \(\lambda _g ^{-1} =\lambda _{g^{-1} }\). We have 
	\[
		\left( \lambda _{g^{-1} }\circ \lambda _g \right)(a) = g^{-1} g a = a = \lambda _e (a)
	\]
	Therefore \(\overline{G} \) is a group under function composition. Now define the isomorphism \(\phi :G\to \overline{G} \) as the map \(g\mapsto \lambda _g\). Trivially, \(\phi \) is surjective. We now show that \(\phi \) is injective. Suppose \(g,h\in G\). Then it follows that 
	\[
		\phi (g)=\lambda _g
	\]
	and
	\[
		\phi (h)=\lambda _h
	\]
	Suppose \(\lambda _h = \lambda _g\). For any \(a\in G\),
	\[
		ga = \lambda _g(a)=\lambda _h(a)=ha
	\]
	Thus, \(\phi \) is injective. Finally, we show that \(\phi \) defines an isomorphism.
	\[
		\phi (gh)=\lambda_{gh}=\lambda_g \lambda _h = \phi (g)\phi (h) 
	\]
	Therefore, \(G\cong \overline{G} \).
\end{longproof}
\begin{remark}
	The isomorphism in the above proof gives the \textbf{left} \textbf{regular} \textbf{representation} of \(G\).
\end{remark}
\section{Direct Products}
Direct products allow the study of groups via Cartesian products of groups.
\subsection{External Direct Products}
\begin{definition}[External Direct Product]
	Let \((G,\cdot),(H,\circ )\) be groups. We define the \textbf{external} \textbf{direct} \textbf{product} of \(G\) and \(H\) as the Cartesian product \(G\times H\), where for any \((g_1,h_1),(g_2,h_2)\in G\times H\), we define the binary operation as 
	\[
		(g_1,h_1)(g_2,h_2)=(g_1\cdot g_2,h_{1}\circ h_2 )
	\]
\end{definition}
\begin{remark}
	The external direct product can be repeated an arbitrary number of times:
	\[
		\prod_{i=1}^n G_i = G_1 \times \cdots \times G_n
	\]
	If all these groups are equivalent, we often simply write \(G^n\).
\end{remark}
\begin{proposition}
	Let \(G\) and \(H\) be groups. The external direct product \(G\times H\) is a group.
\end{proposition}
\begin{proof}
	Let \((g_1,h_1),(g_2,h_2)\in G\times H\). We have
	\[
		(g_1,h_1)(g_2,h_2)=(g_1 g_2,h_1 h_2)
	\]
	Since \(G\) and \(H\) are closed under their respective group operations, \(g_1 g_2 \in G\) and \(h_1 h_2 \in H\), and thus \((g_1 g_2,h_1 h_2)\in G\times H\).\\
	Let \(e_1\) be the identity of \(G\) and \(e_2\) the identity of \(H\), and note that \((e_1,e_2)\in G\times H\). Then we have 
	\[
		(g_1,h_1)(e_1,e_2)=(g_1 e_1,h_1 e_2)=(g_1,h_1)
	\]
	since each is an identity under their own group. Therefore, \(G\times H\) has an identity.\\
	For any \((g,h)\in G\times H\), we can define the identity \(\left( g^{-1} ,h^{-1}  \right)\in G\times H \):
	\[
		(g,h)\left( g^{-1} ,h^{-1}  \right) = \left( gg^{-1} ,hh^{-1}  \right) =\left( e_1,e_2 \right) 
	\]
	Associativity is effort to prove but similarly to the first three it follows directly from the fact that \(G\) and \(H\) are groups.
\end{proof}
\begin{theorem}
	Let \((g,h)\in G\times H\). If \(g\) and \(h\) have finite orders \(r\) and \(s\) respectively, then the order of \((g,h)\) in \(G\times H\) is the least common multiple of \(r\) and \(s\).
\end{theorem}
\begin{proof}
	This should be blatantly obvious I don't know why this proof is so long, but there must be some reason. Anyways if \((g,h)^m = \left( g^m,h^m \right)=(e_G,e_H) \) then \(m\) must be some multiple of both \(r\) and \(s\) in order for this to occur. Thus, the least common multiple must be the order.
\end{proof}
\begin{corollary}
	Let \((g_1,\ldots,g_n)\in \prod G_i\). If \(g_i\) has finite order \(r_i\) in \(G_i\), then the order of \((g_1,\ldots,g_n)\in \prod G_i\) is the least common multiple of \(r_1,\ldots,r_n\).
\end{corollary}

\end{document}